{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e196e0",
   "metadata": {},
   "source": [
    "# LTFS Versioned Object Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ff49e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Background\n",
    "----------\n",
    "\n",
    "The LTFS Versioned Object Format (LTFS-VOF) is a format for saving object data to tapes. This document describes the format so that others may create compatible systems or tools. Python code is included which implements decoding of LTFS-VOF data and metadata. You can download and use this Jupyter notebook interactively to decode your own data.\n",
    "\n",
    "This specification overlays the Linear Tape File System (LTFS). An\n",
    "implementation of the Vail Tape Format will want to refer to the [LTFS\n",
    "specification][ltfs] or use a pre-built LTFS driver. LTFS provides a\n",
    "format for storing files on tape with a POSIX programming interface.\n",
    "The Versioned Object Format layers on top of one or more LTFS tapes to provide:\n",
    "\n",
    "[ltfs]: https://www.snia.org/tech_activities/standards/curr_standards/ltfs\n",
    "\n",
    "1. Efficient object and metadata packing. LTFS-VOF uses large files on\n",
    "   LTFS, which both minimizes the overhead of LTFS metadata and tape\n",
    "   load/unload time.\n",
    "\n",
    "2. Support for very small and very large object sizes. Very small\n",
    "   objects will be packed into large LTFS files, allowing rapid\n",
    "   transfer of many small objects to/from tape. Very large objects may\n",
    "   span tapes.\n",
    "\n",
    "3. S3-compliant object versioning. Unlike POSIX, objects in LTFS-VOF may\n",
    "   have multiple versions, including delete markers.\n",
    "\n",
    "4. S3-compliant object names and metadata. POSIX and S3 have different\n",
    "   naming restrictions and differences in the format of metadata. LTFS-VOF\n",
    "   captures object metadata in LTFS files, similar to object data.\n",
    "\n",
    "5. Modern compression, encryption, and hash codes. LTFS-VOF uses Zstandard\n",
    "   compression, which allows users a great deal of flexibility to\n",
    "   trade off speed vs. compression efficiency. AES-256 encryption is\n",
    "   used, with flexible AES key identifiers that may reference Amazon\n",
    "   Web Services KMS. Data integrity is assured with modern hash codes\n",
    "   such as XXHash.\n",
    "\n",
    "6. Support for tape-set parity. In configurations with multiple tape\n",
    "   libraries, parity packs may be stored to maximize data availability\n",
    "   in the event that a library is down or a set of tapes is damaged.\n",
    "\n",
    "In addition to LTFS, a LTFS-VOF implementation uses [MessagePack][msgpack] to encode various structures. MessagePack implementations are available for most programming languages.\n",
    "\n",
    "[msgpack]: https://msgpack.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c13c6",
   "metadata": {},
   "source": [
    "Object System Concepts\n",
    "----------------------\n",
    "\n",
    "S3-compatible object stores have different concepts and terminology than file systems. This section provides an overview.\n",
    "\n",
    "![Buckets, Objects, Versions](http://joshcarter.com/temp-spectra/concepts1.pdf)\n",
    "\n",
    "### Buckets\n",
    "\n",
    "A *bucket* is the outermost container for objects; it is most similar\n",
    "to a file system. Buckets tend to have high-level policies that apply\n",
    "to all objects within them, for example lifecycle policies that\n",
    "control where data is placed and when tape copies are mode.\n",
    "\n",
    "### Objects and Versions\n",
    "\n",
    "Buckets contain *objects*. Each object has a name (or key) and other\n",
    "metadata associated with it, and a map of data blocks. Objects have\n",
    "one or more *versions*. The last version for a given name is called\n",
    "the *current version*. The object may be thought of as a pointer to\n",
    "the current version. To avoid confusion, this document will almost\n",
    "exclusively discuss versions instead of objects.\n",
    "\n",
    "In addition to the object data, a version has metadata about the version record itself, for example the version's ID, ETag, and creation time. The version metadata is also saved to tape so that the tape set will contain both the data and metadata for all objects.\n",
    "\n",
    "![Blocks and Packs](http://joshcarter.com/temp-spectra/concepts2.pdf)\n",
    "\n",
    "### Blocks\n",
    "\n",
    "A version's data is stored in one or more *blocks*. Each block is a\n",
    "slice of object data, typically 10MB in size before compression. An\n",
    "object whose length is less than the block length will simply be\n",
    "composed of one short block. A larger object will be composed of\n",
    "multiple blocks with a short block at the end. Each block is\n",
    "compressed and encrypted individually so that a S3 client performing\n",
    "range reads may be answered by decoding only the blocks containing the\n",
    "range the client is asking for.\n",
    "\n",
    "A set of blocks are stored together in *packs*. Packs are typically\n",
    "large files, where the optimal pack size is determined by the type of\n",
    "storage media. For tape, packs will be multiple gigabytes in size, and\n",
    "will contain hundreds of blocks stored end-to-end. Packs may contain\n",
    "blocks belonging to many versions.\n",
    "\n",
    "Packs will also contain metadata in the form of pack lists and version records, not just blocks. This metadata allows a tape set to be fully self-describing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa079b",
   "metadata": {},
   "source": [
    "Tape Format Overview\n",
    "--------------------\n",
    "\n",
    "The LTFS Versioned Object Format is composed of several levels. At each level is\n",
    "an encoding scheme that is straightforward to implement, while\n",
    "providing high runtime efficiency. This section presents an overview\n",
    "of each level, with detailed descriptions in following sections.\n",
    "\n",
    "![Levels](http://joshcarter.com/temp-spectra/levels.pdf)\n",
    "\n",
    "\n",
    "### Level 0: LTFS\n",
    "\n",
    "The base (zero) level in the system is LTFS, as specified by the LTFS\n",
    "Format Specification version 2 or later. Any LTFS-compliant driver may\n",
    "be used. The LTFS-VOF should be implemented in a user-space\n",
    "process, using standard POSIX file system calls to manipulate the\n",
    "files on a LTFS tape. LTFS uses a combination of data blocks, index\n",
    "blocks, and file marks to lay out data on a tape. This is entirely\n",
    "transparent to the Vail Tape Format, however.\n",
    "\n",
    "### Level 1: Packs\n",
    "\n",
    "The first level is *packs*, which are LTFS files that store encoded\n",
    "data or metadata. Each pack stores either object data in the form of\n",
    "*blocks*, or metadata in the form of *versions*. Both are described in\n",
    "later sections.\n",
    "\n",
    "LTFS may use one or more extents to store a file, and each extent is a\n",
    "series of data blocks followed by an index block describing the\n",
    "extent. LTFS also stores the index block in a separate index partition\n",
    "which is read when a tape is mounted. Level one is also mostly\n",
    "transparent to a LTFS-VOF implementation.\n",
    "\n",
    "### Level 2: TLV\n",
    "\n",
    "The second level is an end-to-end stacking of records within packs.\n",
    "Each record is encoded with a tag-length-value (TLV) format that uses a\n",
    "fixed-size header and variable-length value. This header contains the\n",
    "minimal information required to identify the type of data stored, its\n",
    "length, and hash codes to validate both the header's integrity and the\n",
    "value's integrity. Any TLV may be read and decoded by simply reading\n",
    "its range of bytes within the pack.\n",
    "\n",
    "### Level 3: Value Encoding\n",
    "\n",
    "The third level uses a variable-size header that provides details on\n",
    "compression, encryption, and the application version used to encode\n",
    "the value. MessagePack is used to decode the header first, then the\n",
    "value contents must be decrypted and decompressed, then those\n",
    "block/version bytes are decoded.\n",
    "\n",
    "### Level 4: Data and Metadata\n",
    "\n",
    "The final level is the LTFS-VOF data and metadata objects. These are the\n",
    "version records, pack lists, and data blocks which comprise all the data\n",
    "stored in the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57057254",
   "metadata": {},
   "source": [
    "Pack Files\n",
    "----------\n",
    "\n",
    "Packs are named with a [ULID][ulid] followed by the extension `.blk`\n",
    "for packs containing blocks, or `.ver` for packs containing versions.\n",
    "Blocks and versions are stored separately so that a system importing a\n",
    "set of tapes need only scan the `.ver` packs to build its database of\n",
    "metadata.\n",
    "\n",
    "[ulid]: https://github.com/oklog/ulid\n",
    "\n",
    "ULID is similar to a UUID, however it contains an embedded timestamp\n",
    "and sorts lexicographically from oldest time to newest time. Pack IDs\n",
    "should use the current time (in UTC) when the pack is first written to.\n",
    "\n",
    "Pack files should be stored in the root directory of a LTFS tape.\n",
    "\n",
    "It is important for read performance that pack files be stored as long\n",
    "runs of contiguous LTFS data extents. While LTFS supports interleaving\n",
    "of file data--which may happen if multiple files are written\n",
    "concurrently--this is not very efficient, as reading such a file will\n",
    "require LTFS to perform many seeks. Therefore it is strongly\n",
    "recommended that a LTFS-VOF writer sequentially write full packs to tape,\n",
    "one pack at a time, so that packs may be composed of large LTFS\n",
    "extents without on-tape interleaving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b0811",
   "metadata": {},
   "source": [
    "TLV Encoding\n",
    "------------\n",
    "\n",
    "![TLV Header](http://joshcarter.com/temp-spectra/tlv_header.pdf)\n",
    "\n",
    "The tag-length-value (TLV) format is used to store many records into a\n",
    "pack file. Its role is to provide just enough information for an\n",
    "application to scan through a pack file, hop from one TLV to the next,\n",
    "and ensure that records are valid before attempting to decode them.\n",
    "\n",
    "TLV uses a 32 byte header and variable-length value. A TLV reader\n",
    "should read the header and validate it using these steps, as illustrated in `read_tlv_header()` below:\n",
    "\n",
    "1. The header \"magic\" is correct. The sequence should match\n",
    "   `0x89`, `T`, `L`, `V`, `0x0d`, `0x0a`, `0x1a`, `0x0a`. This\n",
    "   sequence identifies the TLV and allows early detection of certain\n",
    "   types of corruption, for example end-of-line mangling if the TLV\n",
    "   was accidentally treated as text. (The header magic is borrowed\n",
    "   from the PNG file format. Further detail on its rationale may be\n",
    "   found in the [PNG file format specification][png]).\n",
    "\n",
    "2. The version at byte 24 indicates the version of the\n",
    "   TLV format used when this TLV was created. This is currently 0. Decoding\n",
    "   should stop if an unknown version number is seen.\n",
    "\n",
    "3. At this point the header hash should be calculated and verified.\n",
    "   The hash type is stored at byte 27, and header hash value is stored at bytes 30..31.\n",
    "   Hash type 8, XXHash64, is standard. This is validated by\n",
    "   calculating a [XXHash64][xxhash], keeping only the lower 16\n",
    "   bits, and comparing those to the stored value. Decoding should stop\n",
    "   if the header hash code does not match.\n",
    "\n",
    "The following code demonstrates reading and unpacking the TLV header.\n",
    "\n",
    "[png]: http://www.libpng.org/pub/png/spec/1.2/PNG-Rationale.html#R.PNG-file-signature\n",
    "\n",
    "[xxhash]: http://cyan4973.github.io/xxHash/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb46e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary Python modules for the code in this notebook.\n",
    "# Uncomment following two lines if you have import failures:\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install xxhash msgpack zstd cryptography\n",
    "\n",
    "# Import modules needed for sample code below\n",
    "import base64, io, msgpack, typing, zstd\n",
    "from pprint import pprint\n",
    "from ulid import ULID\n",
    "from collections import namedtuple\n",
    "from struct import unpack\n",
    "from typing import Optional\n",
    "from xxhash import xxh64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1501527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define namedtuple for TLV header fields\n",
    "TlvHeader = namedtuple('TlvHeader', 'magic dlen dhash version tag hashtype hhash')\n",
    "\n",
    "def read_tlv_header(f: typing.BinaryIO) -> TlvHeader:\n",
    "    '''\n",
    "    Read, validate, and decode one TLV header from a file-like IO, leaving\n",
    "    the IO positioned at the start of the value.\n",
    "    :param f: file-like IO to read from\n",
    "    :return: decoded TLV header tuple\n",
    "    '''\n",
    "    header_raw = f.read(32)\n",
    "\n",
    "    if len(header_raw) < 32:\n",
    "        raise f'TLV header too short; need 32 bytes, got {len(header_raw)}'\n",
    "\n",
    "    h = TlvHeader._make(unpack(\"!8sQQBHBxxH\", header_raw))\n",
    "\n",
    "    if h.magic != b'\\x89TLV\\r\\n\\x1a\\n':\n",
    "        raise 'invalid TLV header magic'\n",
    "\n",
    "    if h.version != 0:\n",
    "        raise f'unknown version {h.version}; can only handle TLV version 0'\n",
    "\n",
    "    if h.hashtype != 8:\n",
    "        raise f'invalid hash type {h.hashtype}; can only handle 8 (xxhash64)'\n",
    "\n",
    "    if h.hhash != (xxh64(header_raw[0:30]).intdigest() % 2 ** 16):\n",
    "        raise 'TLV header hash mismatch'\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e69c0",
   "metadata": {},
   "source": [
    "Now that the header has been unpacked and verified, its remaining fields may be considered trustworthy. The tag at bytes 25..26 is used to identify the data type of the value. The data length at bytes 8..15 is stored in network byte order (big-endian). Finally, The data buffer integrity should then be validated using the hash code stored at bytes 16..23. This uses the same hash type as in step 3 above. (The full 64 bits are used this time, instead of 16, as used for header validation.)\n",
    "\n",
    "To consume the data portion of the TLV, simply read the number of data bytes indicated in the header, and validate using the data hash code from the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1161e9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header: TlvHeader(magic=b'\\x89TLV\\r\\n\\x1a\\n', dlen=14, dhash=16374443882442574646, version=0, tag=17185, hashtype=8, hhash=47892)\n",
      "data: b'data data data'\n"
     ]
    }
   ],
   "source": [
    "def read_tlv(f: typing.BinaryIO) -> (TlvHeader, bytes):\n",
    "    '''\n",
    "    Read a complete TLV from the the file-like IO.\n",
    "    :param f: file-like IO to read from\n",
    "    :return: TLV header tuple and value bytes\n",
    "    '''\n",
    "    header = read_tlv_header(f)\n",
    "    data = f.read(header.dlen)\n",
    "\n",
    "    if len(data) < header.dlen:\n",
    "        raise f'short data read: expected {header.dlen} bytes, got {len(data)}'\n",
    "\n",
    "    if header.dhash != xxh64(data).intdigest():\n",
    "        raise \"TLV data hash mismatch\"\n",
    "\n",
    "    return header, data\n",
    "\n",
    "# Small sample TLV, base64-encoded\n",
    "with io.BytesIO(base64.b64decode(\"iVRMVg0KGgoAAAAAAAAADuM9tfSfjss2AEMhCAAAuxRkYXRhIGRhdGEgZGF0YQ==\")) as f:\n",
    "    header, data = read_tlv(f)\n",
    "    print(f'header: {header}')\n",
    "    print(f'data: {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854dc0ab",
   "metadata": {},
   "source": [
    "Multiple TLVs may be stored end-to-end within a file. The example file `3simple.tlv` has three TLVs with simple strings for values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77f6d5e-226d-49d5-b7b5-2582f30cc8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag 25195 value b'data 1'\n",
      "tag 25195 value b'data 2'\n",
      "tag 25195 value b'data 3'\n"
     ]
    }
   ],
   "source": [
    "with open('sample_data/3simple.tlv', 'rb') as f:\n",
    "    for i in range(3):\n",
    "        header, data = read_tlv(f)\n",
    "        print(f'tag {header.tag} value {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e111fa",
   "metadata": {},
   "source": [
    "# Value Encoding\n",
    "\n",
    "TLV values are encoded using a separate, second level called *value\n",
    "encoding*. This is separate from TLV because:\n",
    "\n",
    "1. TLV allows many items to be stored together and validated without decoding the values. This allows copying TLVs from one site to another, or migrating from one storage medium to another, even if the encryption keys are not accessible.\n",
    "\n",
    "2. Applications may scan through many TLVs looking for a specific one (identified by data hash) and then decode only the TLV it needs.\n",
    "\n",
    "3. TLV requires a fixed-size header by design. The value encoder uses a variable-size header because the encoding may have several stages, and the parameters of each stage will be specified in the header. For example, if the value is encrypted, the header will include crypt-specific details. If not encrypted, these fields will not be present.\n",
    "\n",
    "Value encoding provides the following features:\n",
    "\n",
    "1. Compression, by default using the Zstandard algorithm. If the data is not compressible, then compression may be skipped.\n",
    "   \n",
    "2. Encryption with AES-256.\n",
    "\n",
    "3. Data format versioning. If the application changes its saved data format, it will increment the version number for saved values. Decoding should inspect the version number and decode accordingly.\n",
    "   \n",
    "4. Flexibility for future features. Fields may be added to the header as necessary.\n",
    "\n",
    "[MessagePack][msgpack] is used to serialize both the header and the application-defined data. High-quality implementations of MessagePack are available for most programming languages. MessagePack is a fast, compact, binary encoding format.\n",
    "\n",
    "[msgpack]: https://msgpack.org/index.html\n",
    "\n",
    "![Value Encoding](http://joshcarter.com/temp-spectra/value_encoding.pdf)\n",
    "\n",
    "An encoded value has a manadatory first part describing the encoding and containing any structured data, called the primary part. It may also have an optional secondary part. The secondary part, if present, will be raw bytes which are usually compressed and/or encrypted in the same manner as the primary part.\n",
    "\n",
    "## Primary Part Decode\n",
    "\n",
    "The following code shows how to decode a value. In a nutshell, the process is:\n",
    "\n",
    "1. MessagePack decode the value, using the provided structure\n",
    "   definitions below. This first pass decodes the header; the\n",
    "   value's primary part remains encoded in the `e` field. In\n",
    "   following steps, the term *primary part* will refer to bytes\n",
    "   that are initially stored in `e` field and get passed through\n",
    "   the various decoding steps below.\n",
    "   \n",
    "2. If key `z` (crypt info) is provided, then the primary part\n",
    "   must be decrypted. Details on cipher setup and key identification follow\n",
    "   in later sections.\n",
    "   \n",
    "3. If key `c` (compression type) is provided, then use the appropriate\n",
    "   algorithm to decompress the primary part. Zstandard is the\n",
    "   default algorithm.\n",
    "\n",
    "4. The key `v` (version) is provided, it will indicate what version of structure is\n",
    "   stored. Currently all LTFS-VOF structures are version zero so key `v` will not be  \n",
    "   present. If breaking changes are made to the format, this number will\n",
    "   indicate which version is stored.\n",
    "   \n",
    "5. Now that the primary part's type is known (from TLV decode) and the\n",
    "   version is known (from prior step), use MessagePack to decode the\n",
    "   primary part into the appropriate data structure.\n",
    "   \n",
    "## Secondary Part Decode\n",
    "\n",
    "The secondary part has its own encoding parameters. Note that this field is a list to allow for multiple secondary parts. In its current form LTFS-VOF will only use one secondary part in a value.\n",
    "\n",
    "If key `s` is provided for secondary encoding parameters, the mandatory sub-key `l` will specify the encoded length of the secondary part. For all other secondary encoding parameters, they should be assumed to match the encoding of the primary part unless explicitly overridden in the secondary encoding structure.\n",
    "\n",
    "Whereas the primary part is always encoded with MessagePack, the secondary part will be raw bytes. In LTFS-VOF only data blocks will have a secondary part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742593ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'value 1 header'\n",
      "b'value 1 data'\n",
      "b'value 2 header'\n",
      "b'value 2 data'\n",
      "b'value 3 header'\n",
      "b'value 3 data'\n"
     ]
    }
   ],
   "source": [
    "def decode_value(f: typing.BinaryIO, dlen: int) -> (dict, Optional[bytes]):\n",
    "    unpacker = msgpack.Unpacker(f)\n",
    "    val = unpacker.unpack()\n",
    "\n",
    "    if 'z' in val:\n",
    "        raise 'encrypted values not supported'  # TODO: decrypt\n",
    "\n",
    "    # Decompress encoded value if compressed\n",
    "    if val.get('c') == 1:\n",
    "        val['e'] = zstd.decompress(val['e'])\n",
    "\n",
    "    primary = msgpack.unpackb(val['e'])\n",
    "    secondary = bytes(0)\n",
    "\n",
    "    try:\n",
    "        sec_enc = val['s'][0]  # Encoding specifier of secondary part\n",
    "        sec_len = sec_enc['l']  # Length of secondary part\n",
    "        f.seek(dlen - sec_len)  # MsgPack may have read the secondary part already, so seek back to it\n",
    "        secondary = f.read(sec_len)\n",
    "\n",
    "        # If secondary encoding specifies compression, or that key is missing and primary encoding specifies\n",
    "        # compression, then decompress the secondary value.\n",
    "        if sec_enc.get('c', val.get('c')) == 1:\n",
    "            secondary = zstd.decompress(secondary)\n",
    "    except IndexError:\n",
    "        pass  # no secondary part\n",
    "    except KeyError:\n",
    "        pass  # no secondary part\n",
    "\n",
    "    return primary, secondary\n",
    "\n",
    "\n",
    "with open('sample_data/3values.tlv', 'rb') as f:\n",
    "    for i in range(3):\n",
    "        header, data = read_tlv(f)\n",
    "        primary, secondary = decode_value(io.BytesIO(data), header.dlen)\n",
    "        pprint(primary)\n",
    "        pprint(secondary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169c3b7",
   "metadata": {},
   "source": [
    "# Blocks and Pack Lists\n",
    "\n",
    "The values in LTFS Versioned Object Format may be of one of three types:\n",
    "\n",
    "1. Blocks, which store data.\n",
    "\n",
    "2. Pack list metadata, which describe how blocks are arranged into versions.\n",
    "\n",
    "3. Version metadata, which are described in a later section.\n",
    "\n",
    "This section describes blocks and pack lists. As data enters a LTFS-VOF system, it is split into slices (default 10MB in size) and each slice becomes a block. A version will have one or more blocks. In addition, a pack list is created which shows which ranges of a version are mapped to which ranges of each block.\n",
    "\n",
    "## Blocks\n",
    "\n",
    "Each stored block will have a primary part and secondary part. The primary part will only have key `I` which specifies the composite version ID this block belongs to. The secondary part will contain the raw bytes for the block.\n",
    "\n",
    "### Composite Version IDs\n",
    "\n",
    "A composite Version ID is a combination of the bucket name, object name, and a unique ULID for the version. The format is:\n",
    "\n",
    "    [26 byte version ULID]:bucketname/objectname\n",
    "\n",
    "The `bucketname` will be a bucket name that complies with AWS S3 bucket naming conventions. The `objectname` will be any S3 compliant object name. Note, when parsing, that an object name may contain slashes.\n",
    "\n",
    "The following sample code demonstrates parsing a composite version ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6202b6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VersionID(bucket='bucket', object='object/name.txt', version=ULID(7YGGZJ4YSFMYW6BQVHFKD5KKTV))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VersionID = namedtuple('VersionID', 'bucket object version')\n",
    "\n",
    "def parse_versionid(version_str: str) -> VersionID:\n",
    "    # First 26 characters is a ULID specifying the version\n",
    "    version = ULID.from_str(version_str[:26])\n",
    "    # Remaining characters (after a ':' separator) are bucket/object name\n",
    "    bucket, object = version_str[27:].split('/', maxsplit=1)\n",
    "    # Together these form the complete version identifier\n",
    "    return VersionID(bucket=bucket, object=object, version=version)\n",
    "\n",
    "parse_versionid('7YGGZJ4YSFMYW6BQVHFKD5KKTV:bucket/object/name.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6924667",
   "metadata": {},
   "source": [
    "## Pack Lists\n",
    "\n",
    "In the following figure, consider a version which is split into five blocks, and those blocks are stored across two packs.\n",
    "\n",
    "<img src=\"http://joshcarter.com/temp-spectra/pack_list.pdf\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd6c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
