{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0764d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary Python modules for the code in this notebook.\n",
    "# Uncomment following two lines if you have import failures:\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install xxhash msgpack zstd cryptography\n",
    "\n",
    "# Import modules needed for sample code below\n",
    "import base64, io, typing, msgpack, zstd\n",
    "from collections import namedtuple\n",
    "from struct import pack, unpack\n",
    "from cryptography.hazmat.primitives.ciphers.aead import AESGCM\n",
    "from xxhash import xxh64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ff49e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Background\n",
    "----------\n",
    "\n",
    "Vail is a S3-compatible object storage system created by Spectra\n",
    "Logic, featuring lifecycle policies that can store object data to\n",
    "tape. The Vail Tape Format (VTF) specifies the format of these tapes,\n",
    "so that others may create compatible systems or tools.\n",
    "\n",
    "This specification overlays the Linear Tape File System (LTFS). An\n",
    "implementation of the Vail Tape Format will want to refer to the [LTFS\n",
    "specification][ltfs] or use a pre-built LTFS driver. LTFS provides a\n",
    "format for storing files on tape with a POSIX programming interface.\n",
    "The Vail Tape Format layers on top of a set of LTFS tapes to provide:\n",
    "\n",
    "[ltfs]: https://www.snia.org/tech_activities/standards/curr_standards/ltfs\n",
    "\n",
    "1. Efficient object and metadata packing. VTF uses large files on\n",
    "   LTFS, which both minimizes the overhead of LTFS metadata and tape\n",
    "   load/unload time.\n",
    "\n",
    "2. Support for very small and very large object sizes. Very small\n",
    "   objects will be packed into large LTFS files, allowing rapid\n",
    "   transfer of many small objects to/from tape. Very large objects may\n",
    "   span tapes.\n",
    "\n",
    "3. S3-compliant object versioning. Unlike POSIX, objects in VTF may\n",
    "   have multiple versions, including delete markers.\n",
    "\n",
    "4. S3-compliant object names and metadata. POSIX and S3 have different\n",
    "   naming restrictions and differences in the format of metadata. VTF\n",
    "   captures object metadata in LTFS files, similar to object data.\n",
    "\n",
    "5. Modern compression, encryption, and hash codes. VTF uses Zstandard\n",
    "   compression, which allows users a great deal of flexibility to\n",
    "   trade off speed vs. compression efficiency. AES-256 encryption is\n",
    "   used, with flexible AES key identifiers that may reference Amazon\n",
    "   Web Services KMS. Data integrity is assured with modern hash codes\n",
    "   such as XXHash.\n",
    "\n",
    "6. Support for tape-set parity. In configurations with multiple tape\n",
    "   libraries, parity packs may be stored to maximize data availability\n",
    "   in the event that a library is down or a set of tapes is damaged.\n",
    "\n",
    "In addition to LTFS, a VTF implementation uses [MessagePack][msgpack]\n",
    "to encode various VTF structures. MessagePack implementations are\n",
    "available for most programming languages.\n",
    "\n",
    "[msgpack]: https://msgpack.org/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e3c13c6",
   "metadata": {},
   "source": [
    "Object System Concepts\n",
    "----------------------\n",
    "\n",
    "Vail, and other S3-compatible object stores, have different concepts\n",
    "and terminology than file systems. This section provides an overview.\n",
    "\n",
    "![Buckets, Objects, and Versions](http://joshcarter.com/temp-spectra/concepts1.pdf)\n",
    "\n",
    "<img src=\"http://joshcarter.com/temp-spectra/concepts1.png\" alt=\"Buckets, Objects, Versions\" width=\"75% />\n",
    "\n",
    "### Buckets\n",
    "\n",
    "A *bucket* is the outermost container for objects; it is most similar\n",
    "to a file system. Buckets tend to have high-level policies that apply\n",
    "to all objects within them, for example lifecycle policies that\n",
    "control where data is placed and when tape copies are mode.\n",
    "\n",
    "### Objects and Versions\n",
    "\n",
    "Buckets contain *objects*. Each object has a name (or key) and other\n",
    "metadata associated with it, and a map of data blocks. Objects have\n",
    "one or more *versions*. The last version for a given name is called\n",
    "the *current version*. The object may be thought of as a pointer to\n",
    "the current version. To avoid confusion, this document will almost\n",
    "exclusively discuss versions instead of objects.\n",
    "\n",
    "Vail stores its version records in a database separate from the\n",
    "storage pools. When saving versions to tape, it also makes backups of\n",
    "the version records so that the tape set will contain both the data\n",
    "and metadata for all objects on tape.\n",
    "\n",
    "![Blocks and Packs](http://joshcarter.com/temp-spectra/concepts2.pdf)\n",
    "\n",
    "### Blocks\n",
    "\n",
    "A version's data is stored in one or more *blocks*. Each block is a\n",
    "slice of object data, typically 10MB in size before compression. An\n",
    "object whose length is less than the block length will simply be\n",
    "composed of one short block. A larger object will be composed of\n",
    "multiple blocks with a short block at the end. Each block is\n",
    "compressed and encrypted individually so that a S3 client performing\n",
    "range reads may be answered by decoding only the blocks containing the\n",
    "range the client is asking for.\n",
    "\n",
    "A set of blocks are stored together in *packs*. Packs are typically\n",
    "large files, where the optimal pack size is determined by the type of\n",
    "storage media. For tape, packs will be multiple gigabytes in size, and\n",
    "will contain hundreds of blocks stored end-to-end. Packs may contain\n",
    "blocks belonging to many versions.\n",
    "\n",
    "Packs may also contain version records, not just blocks. These version\n",
    "packs allow a tape set to be fully self-describing.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15fa079b",
   "metadata": {},
   "source": [
    "Tape Format Overview\n",
    "--------------------\n",
    "\n",
    "The Vail Tape Format is composed of several levels. At each level is\n",
    "an encoding scheme that is straightforward to implement, while\n",
    "providing high runtime efficiency. This section presents an overview\n",
    "of each level, with detailed descriptions in following sections.\n",
    "\n",
    "![Levels](http://joshcarter.com/temp-spectra/levels.pdf)\n",
    "\n",
    "### Level 0: LTFS\n",
    "\n",
    "The base (zero) level in the system is LTFS, as specified by the LTFS\n",
    "Format Specification version 2 or later. Any LTFS-compliant driver may\n",
    "be used. The Vail Tape Format should be implemented in a user-space\n",
    "process, using standard POSIX file system calls to manipulate the\n",
    "files on a LTFS tape. LTFS uses a combination of data blocks, index\n",
    "blocks, and file marks to lay out data on a tape. This is entirely\n",
    "transparent to the Vail Tape Format, however.\n",
    "\n",
    "### Level 1: Packs\n",
    "\n",
    "The first level is *packs*, which are LTFS files that store encoded\n",
    "data or metadata. Each pack stores either object data in the form of\n",
    "*blocks*, or metadata in the form of *versions*. Both are described in\n",
    "later sections.\n",
    "\n",
    "LTFS may use one or more extents to store a file, and each extent is a\n",
    "series of data blocks followed by an index block describing the\n",
    "extent. LTFS also stores the index block in a separate index partition\n",
    "which is read when a tape is mounted. Level one is also mostly\n",
    "transparent to a VTF implementation.\n",
    "\n",
    "### Level 2: TLV\n",
    "\n",
    "The second level is an end-to-end stacking of records within packs.\n",
    "Each record is encoded with a tag-length-value (TLV) format that uses a\n",
    "fixed-size header and variable-length value. This header contains the\n",
    "minimal information required to identify the type of data stored, its\n",
    "length, and hash codes to validate both the header's integrity and the\n",
    "value's integrity. Any TLV may be read and decoded by simply reading\n",
    "its range of bytes within the pack. Pack files do not contain a header\n",
    "or footer.\n",
    "\n",
    "### Level 3: Value Encoding\n",
    "\n",
    "The third level uses a variable-size header that provides details on\n",
    "compression, encryption, and the application version used to encode\n",
    "the value. MessagePack is used to decode the header first, then the\n",
    "value contents must be decrypted and decompressed, then those\n",
    "block/version bytes are decoded using MessagePack. MessagePack is a\n",
    "fast and lightweight binary encoding format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57057254",
   "metadata": {},
   "source": [
    "Pack Files\n",
    "----------\n",
    "\n",
    "Packs are named with a [ULID][ulid] followed by the extension `.blk`\n",
    "for packs containing blocks, or `.ver` for packs containing versions.\n",
    "Blocks and versions are stored separately so that a system importing a\n",
    "set of tapes need only scan the `.ver` packs to build its database of\n",
    "metadata.\n",
    "\n",
    "[ulid]: https://github.com/oklog/ulid\n",
    "\n",
    "ULID is similar to a UUID, however it contains an embedded timestamp\n",
    "and sorts lexicographically from oldest time to newest time. Vail\n",
    "creates a pack identifier using the current time (in UTC) when the\n",
    "pack is first written to.\n",
    "\n",
    "Pack files will be stored in the root directory of a LTFS tape.\n",
    "\n",
    "It is important for read performance that pack files be stored as long\n",
    "runs of contiguous LTFS data extents. While LTFS supports interleaving\n",
    "of file data--which may happen if multiple files are written\n",
    "concurrently--this is not very efficient, as reading such a file will\n",
    "require LTFS to perform many seeks. Therefore it is strongly\n",
    "recommended that a VTF writer sequentially write a full packs to tape,\n",
    "one pack at a time, so that packs may be composed of large LTFS\n",
    "extents without on-tape interleaving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b0811",
   "metadata": {},
   "source": [
    "TLV Encoding\n",
    "------------\n",
    "\n",
    "![TLV Header](http://joshcarter.com/temp-spectra/tlv_header.pdf)\n",
    "\n",
    "The tag-length-value (TLV) format is used to pack many records into a\n",
    "pack file. Its role is to provide just enough information for an\n",
    "application to scan through a pack file, hop from one TLV to the next,\n",
    "and ensure that records are valid before attempting to decode them.\n",
    "\n",
    "TLV uses a 32 byte header and variable-length value. A TLV reader\n",
    "should read the header and validate it using these steps, as illustrated in `read_tlv_header()` below:\n",
    "\n",
    "1. The header \"magic\" is correct. The sequence should match\n",
    "   `0x89`, `T`, `L`, `V`, `0x0d`, `0x0a`, `0x1a`, `0x0a`. This\n",
    "   sequence identifies the TLV and allows early detection of certain\n",
    "   types of corruption, for example end-of-line mangling if the TLV\n",
    "   was accidentally treated as text. (The header magic is borrowed\n",
    "   from the PNG file format. Further detail on its rationale may be\n",
    "   found in the [PNG file format specification][png]).\n",
    "\n",
    "2. The version at byte 24 indicates the version of the\n",
    "   TLV format used when this TLV was created. This is currently 0. Decoding\n",
    "   should stop if an unknown version number is seen.\n",
    "\n",
    "3. At this point the header hash should be calculated and verified.\n",
    "   The hash type is stored at byte 27, and header hash value is stored at bytes 30..31.\n",
    "   Hash type 8, XXHash64, is standard. This is validated by\n",
    "   calculating a [XXHash64][xxhash], keeping only the lower 16\n",
    "   bits, and comparing those to the stored value. Decoding should stop\n",
    "   if the header hash code does not match.\n",
    "\n",
    "The following code demonstrates reading and unpacking the TLV header.\n",
    "\n",
    "[png]: http://www.libpng.org/pub/png/spec/1.2/PNG-Rationale.html#R.PNG-file-signature\n",
    "\n",
    "[xxhash]: http://cyan4973.github.io/xxHash/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1501527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define namedtuple for TLV header fields\n",
    "TlvHeader = namedtuple('TlvHeader', 'magic dlen dhash version tag hashtype hhash')\n",
    "\n",
    "def read_tlv_header(f: typing.BinaryIO) -> TlvHeader:\n",
    "    '''\n",
    "    Read, validate, and decode one TLV header from a file-like IO, leaving\n",
    "    the IO positioned at the start of the value.\n",
    "    :param f: file-like IO to read from\n",
    "    :return: decoded TLV header tuple\n",
    "    '''\n",
    "    header_raw = f.read(32)\n",
    "\n",
    "    if len(header_raw) < 32:\n",
    "        raise f'TLV header too short; need 32 bytes, got {len(header_raw)}'\n",
    "\n",
    "    h = TlvHeader._make(unpack(\"!8sQQBHBxxH\", header_raw))\n",
    "\n",
    "    if h.magic != b'\\x89TLV\\r\\n\\x1a\\n':\n",
    "        raise 'invalid TLV header magic'\n",
    "\n",
    "    if h.version != 0:\n",
    "        raise f'unknown version {h.version}; can only handle TLV version 0'\n",
    "\n",
    "    if h.hashtype != 8:\n",
    "        raise f'invalid hash type {h.hashtype}; can only handle 8 (xxhash64)'\n",
    "\n",
    "    if h.hhash != (xxh64(header_raw[0:30]).intdigest() % 2 ** 16):\n",
    "        raise 'TLV header hash mismatch'\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e69c0",
   "metadata": {},
   "source": [
    "Now that the header has been unpacked and verified, its remaining fields may be considered trustworthy. The tag at bytes 25..26 is used to identify the data type of the value. The data length at bytes 8..15 is stored in network byte order (big-endian). Finally, The data buffer integrity should then be validated using the hash code stored at bytes 16..23. This uses the same hash type as in step 3 above. (The full 64 bits are used this time, instead of 16, as used for header validation.)\n",
    "\n",
    "To consume the data portion of the TLV, simply read the number of data bytes indicated in the header, and validate using the data hash code from the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1161e9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header: TlvHeader(magic=b'\\x89TLV\\r\\n\\x1a\\n', dlen=14, dhash=16374443882442574646, version=0, tag=17185, hashtype=8, hhash=47892)\n",
      "data: b'data data data'\n"
     ]
    }
   ],
   "source": [
    "def read_tlv(f: typing.BinaryIO) -> (TlvHeader, bytes):\n",
    "    '''\n",
    "    Read a complete TLV from the the file-like IO.\n",
    "    :param f: file-like IO to read from\n",
    "    :return: TLV header tuple and value bytes\n",
    "    '''\n",
    "    header = read_tlv_header(f)\n",
    "    data = f.read(header.dlen)\n",
    "\n",
    "    if len(data) < header.dlen:\n",
    "        raise f'short data read: expected {header.dlen} bytes, got {len(data)}'\n",
    "\n",
    "    if header.dhash != xxh64(data).intdigest():\n",
    "        raise \"TLV data hash mismatch\"\n",
    "\n",
    "    return header, data\n",
    "\n",
    "# Small sample TLV, base64-encoded\n",
    "with io.BytesIO(base64.b64decode(\"iVRMVg0KGgoAAAAAAAAADuM9tfSfjss2AEMhCAAAuxRkYXRhIGRhdGEgZGF0YQ==\")) as f:\n",
    "    header, data = read_tlv(f)\n",
    "    print(f'header: {header}')\n",
    "    print(f'data: {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854dc0ab",
   "metadata": {},
   "source": [
    "Multiple TLVs may be stored end-to-end within a file. The example file `3simple.tlv` has three TLVs with simple strings for values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77f6d5e-226d-49d5-b7b5-2582f30cc8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag 25195 value b'data 1'\n",
      "tag 25195 value b'data 2'\n",
      "tag 25195 value b'data 3'\n"
     ]
    }
   ],
   "source": [
    "with open('sample_data/3simple.tlv', 'rb') as f:\n",
    "    for i in range(3):\n",
    "        header, data = read_tlv(f)\n",
    "        print(f'tag {header.tag} value {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e111fa",
   "metadata": {},
   "source": [
    "Value Encoding\n",
    "--------------\n",
    "\n",
    "TLV values are encoded using a separate, second level called *value\n",
    "encoding*. This is separate from TLV because:\n",
    "\n",
    "1. Vail uses the value encoding format in other places, for example to\n",
    "   encode database records. The database records need compression and\n",
    "   encryption, but do not need TLV's tag, length, or hash code, as the\n",
    "   database already handles record type, length, and integrity.\n",
    "\n",
    "2. The encoding steps in TLV are mandatory and, by design, require a\n",
    "   fixed-size (but very small) header. The encoding steps in value\n",
    "   encoding are complimentary to TLV, and each is optional. A\n",
    "   variable-size header is used, and this header only includes the\n",
    "   fields necessary for decoding the value. For example, if the value\n",
    "   is encrypted, the header will include crypt-specific details. If\n",
    "   not encrypted, these fields will not be present.\n",
    "\n",
    "Value encoding provides the following features:\n",
    "\n",
    "1. Compression, by default using the Zstandard algorithm. If the data\n",
    "   is not compressible, then compression may be skipped.\n",
    "   \n",
    "2. Encryption with AES-256.\n",
    "\n",
    "3. Data format versioning. If the application changes its saved data\n",
    "   format, it will increment its version number. When reading values,\n",
    "   the application will need to support multiple versions.\n",
    "\n",
    "TODO: rewrite that bit on #3.\n",
    "   \n",
    "4. Flexibility for future features. Fields may be added to the header\n",
    "   as necessary.\n",
    "\n",
    "[MessagePack][msgpack] is used to serialize both the header and the\n",
    "application-defined data. High-quality implementations of MessagePack\n",
    "are available for most programming languages. MessagePack is a fast,\n",
    "compact, binary encoding format.\n",
    "\n",
    "To decode a value:\n",
    "\n",
    "1. MessagePack decode the value, using the provided structure\n",
    "   definitions below. This first pass decodes the header; the\n",
    "   application data remains encoded in the `Value.Encoded` field. In\n",
    "   following steps, the term *application data* will refer to bytes\n",
    "   that are initially stored in `Value.Encoded` and get passed through\n",
    "   the various decoding steps below.\n",
    "   \n",
    "2. If the `Value.Crypt` structure is provided and\n",
    "   `Value.Crypt.Algorithm` is set to `AES`, then the application data\n",
    "   must be decrypted. The encryption key identifier and cipher setup\n",
    "   will vary depending on how the application set it up. The\n",
    "   application will store any value-specific properties in\n",
    "   `Value.Crypt.CryptData`; see the section \"encryption structures\"\n",
    "   following. The nonce is stored in `Value.Crypt.Nonce`. Finally, use\n",
    "   AES-GCM to decrypt and validate `Value.Encoded`.\n",
    "   \n",
    "3. If `Value.CompressionType` is not `None`, then use the appropriate\n",
    "   algorithm to decompress the application data. Zstandard is the\n",
    "   default algorithm.\n",
    "\n",
    "4. The `Value.Version` will indicate what version of structure is\n",
    "   stored. This is zero by default, and if zero it will be omitted\n",
    "   from the header. Refer to the sections on block/version details for\n",
    "   the structures at each version.\n",
    "   \n",
    "5. Now that the type of the application data is known (from TLV\n",
    "   decode) and the version is known (from prior step), use MessagePack\n",
    "   to decode the application data into the appropriate data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742593ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag 25195 value b'\\x82\\xa1s\\x91\\x81\\xa1l\\x0c\\xa1e\\xc4\\x10\\xc4\\x0evalue 1 headervalue 1 data'\n",
      "tlv len: 40\n",
      "f pos: 0\n",
      "f pos: 40\n",
      "val: {'s': [{'l': 12}], 'e': b'\\xc4\\x0evalue 1 header'}\n",
      "primary: b'value 1 header'\n",
      "secondary: b''\n",
      "tag 25195 value b'\\x82\\xa1s\\x91\\x81\\xa1l\\x0c\\xa1e\\xc4\\x10\\xc4\\x0evalue 2 headervalue 2 data'\n",
      "tlv len: 40\n",
      "f pos: 0\n",
      "f pos: 40\n",
      "val: {'s': [{'l': 12}], 'e': b'\\xc4\\x0evalue 2 header'}\n",
      "primary: b'value 2 header'\n",
      "secondary: b''\n",
      "tag 25195 value b'\\x82\\xa1s\\x91\\x81\\xa1l\\x0c\\xa1e\\xc4\\x10\\xc4\\x0evalue 3 headervalue 3 data'\n",
      "tlv len: 40\n",
      "f pos: 0\n",
      "f pos: 40\n",
      "val: {'s': [{'l': 12}], 'e': b'\\xc4\\x0evalue 3 header'}\n",
      "primary: b'value 3 header'\n",
      "secondary: b''\n"
     ]
    }
   ],
   "source": [
    "def decode_value(f: io.RawIOBase):\n",
    "    print(f'f pos: {f.tell()}')\n",
    "    unpacker = msgpack.Unpacker(f)\n",
    "    val = unpacker.unpack()\n",
    "    print(f'f pos: {f.tell()}')\n",
    "    print(f'val: {val}')\n",
    "    enc = val['e']\n",
    "    \n",
    "    # decrypt\n",
    "    \n",
    "    # decompress\n",
    "    \n",
    "    # inner decode\n",
    "    val1 = msgpack.unpackb(val['e'])\n",
    "    print(f'primary: {val1}')\n",
    "    \n",
    "    # secondary\n",
    "    if val['s'] and len(val['s']) > 0 and val['s'][0]['l']:\n",
    "        sec_len = val['s'][0]['l']\n",
    "        # print(f'sec_len: {sec_len}')\n",
    "        sec = data = f.read(sec_len)\n",
    "        print(f'secondary: {sec}')\n",
    "    \n",
    "\n",
    "\n",
    "with open('sample_data/3values.tlv', 'rb') as f:\n",
    "    for i in range(3):\n",
    "        header, data = read_tlv(f)\n",
    "        print(f'tag {header.tag} value {data}')\n",
    "        print(f'tlv len: {header.dlen}')\n",
    "        decode_value(io.BytesIO(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00bb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
